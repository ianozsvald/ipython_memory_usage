{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25531fd7",
   "metadata": {},
   "source": [
    "# Short demo of using `ipython_memory_usage` to diagnose numpy and Pandas RAM usage\n",
    "\n",
    "Author Ian uses this tool in his Higher Performance Python training (https://ianozsvald.com/training/) and it is mentioned in his High Performance Python (2nd ed, O'Reilly) technical book.\n",
    "\n",
    "We can use it to understand how much RAM we're currently using and which of several alternate ways to solve a problem in complex tools might be the most RAM efficient solutions.\n",
    "\n",
    "* `total RAM usage` is the current RAM usage at the end of that cell's execution\n",
    "* `used` shows the difference between the _last_ `total RAM usage` and this one\n",
    "* `peaked` shows any during-execution peak _above_ the resulting `total RAM usage` (i.e. hidden RAM usage that might catch you out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2954dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package ipython_memory_usage:\n",
      "\n",
      "NAME\n",
      "    ipython_memory_usage - Profile mem usage envelope of IPython commands and report interactively\n",
      "\n",
      "DESCRIPTION\n",
      "    Use \n",
      "    In[] %load_ext ipython_memory_usage\n",
      "    In[] %imu_start # invoke magic-based tracking and\n",
      "    # %imu_stop to disable\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    ipython_memory_usage\n",
      "    ipython_memory_usage_perf\n",
      "    perf_process\n",
      "\n",
      "SUBMODULES\n",
      "    imu\n",
      "\n",
      "CLASSES\n",
      "    IPython.core.magic.Magics(traitlets.config.configurable.Configurable)\n",
      "        IPythonMemoryUsageMagics\n",
      "    \n",
      "    class IPythonMemoryUsageMagics(IPython.core.magic.Magics)\n",
      "     |  IPythonMemoryUsageMagics(shell=None, **kwargs)\n",
      "     |  \n",
      "     |  # The class MUST call this class decorator at creation time\n",
      "     |  # https://ipython.readthedocs.io/en/stable/config/custommagics.html\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IPythonMemoryUsageMagics\n",
      "     |      IPython.core.magic.Magics\n",
      "     |      traitlets.config.configurable.Configurable\n",
      "     |      traitlets.traitlets.HasTraits\n",
      "     |      traitlets.traitlets.HasDescriptors\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  imu_start(self, line)\n",
      "     |      Start CPU & memory profiling for IPython Memory Usage\n",
      "     |  \n",
      "     |  imu_stop(self, line)\n",
      "     |      End profiling for IPython Memory Usage\n",
      "     |  \n",
      "     |  lmagic(self, line)\n",
      "     |      my line magic\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  magics = {'cell': {}, 'line': {'imu_start': 'imu_start', 'imu_stop': '...\n",
      "     |  \n",
      "     |  registered = True\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from IPython.core.magic.Magics:\n",
      "     |  \n",
      "     |  __init__(self, shell=None, **kwargs)\n",
      "     |      Create a configurable given a config config.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      config : Config\n",
      "     |          If this is empty, default values are used. If config is a\n",
      "     |          :class:`Config` instance, it will be used to configure the\n",
      "     |          instance.\n",
      "     |      parent : Configurable instance, optional\n",
      "     |          The parent Configurable instance of this object.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Subclasses of Configurable must call the :meth:`__init__` method of\n",
      "     |      :class:`Configurable` *before* doing anything else and using\n",
      "     |      :func:`super`::\n",
      "     |      \n",
      "     |          class MyConfigurable(Configurable):\n",
      "     |              def __init__(self, config=None):\n",
      "     |                  super(MyConfigurable, self).__init__(config=config)\n",
      "     |                  # Then any other code you need to finish initialization.\n",
      "     |      \n",
      "     |      This ensures that instances will be configured properly.\n",
      "     |  \n",
      "     |  arg_err(self, func)\n",
      "     |      Print docstring if incorrect arguments were passed\n",
      "     |  \n",
      "     |  default_option(self, fn, optstr)\n",
      "     |      Make an entry in the options_table for fn, with value optstr\n",
      "     |  \n",
      "     |  format_latex(self, strng)\n",
      "     |      Format a string for latex inclusion.\n",
      "     |  \n",
      "     |  parse_options(self, arg_str, opt_str, *long_opts, **kw)\n",
      "     |      Parse options passed to an argument string.\n",
      "     |      \n",
      "     |      The interface is similar to that of :func:`getopt.getopt`, but it\n",
      "     |      returns a :class:`~IPython.utils.struct.Struct` with the options as keys\n",
      "     |      and the stripped argument string still as a string.\n",
      "     |      \n",
      "     |      arg_str is quoted as a true sys.argv vector by using shlex.split.\n",
      "     |      This allows us to easily expand variables, glob files, quote\n",
      "     |      arguments, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg_str : str\n",
      "     |          The arguments to parse.\n",
      "     |      opt_str : str\n",
      "     |          The options specification.\n",
      "     |      mode : str, default 'string'\n",
      "     |          If given as 'list', the argument string is returned as a list (split\n",
      "     |          on whitespace) instead of a string.\n",
      "     |      list_all : bool, default False\n",
      "     |          Put all option values in lists. Normally only options\n",
      "     |          appearing more than once are put in a list.\n",
      "     |      posix : bool, default True\n",
      "     |          Whether to split the input line in POSIX mode or not, as per the\n",
      "     |          conventions outlined in the :mod:`shlex` module from the standard\n",
      "     |          library.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from IPython.core.magic.Magics:\n",
      "     |  \n",
      "     |  options_table = None\n",
      "     |  \n",
      "     |  shell = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from traitlets.config.configurable.Configurable:\n",
      "     |  \n",
      "     |  update_config(self, config: 'Config') -> 'None'\n",
      "     |      Update config and load the new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from traitlets.config.configurable.Configurable:\n",
      "     |  \n",
      "     |  class_config_rst_doc() -> 'str' from traitlets.traitlets.MetaHasTraits\n",
      "     |      Generate rST documentation for this class' config options.\n",
      "     |      \n",
      "     |      Excludes traits defined on parent classes.\n",
      "     |  \n",
      "     |  class_config_section(classes: 't.Sequence[type[HasTraits]] | None' = None) -> 'str' from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get the config section for this class.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      classes : list, optional\n",
      "     |          The list of other classes in the config file.\n",
      "     |          Used to reduce redundant information.\n",
      "     |  \n",
      "     |  class_get_help(inst: 'HasTraits | None' = None) -> 'str' from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get the help string for this class in ReST format.\n",
      "     |      \n",
      "     |      If `inst` is given, its current trait values will be used in place of\n",
      "     |      class defaults.\n",
      "     |  \n",
      "     |  class_get_trait_help(trait: 'TraitType[t.Any, t.Any]', inst: 'HasTraits | None' = None, helptext: 'str | None' = None) -> 'str' from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get the helptext string for a single trait.\n",
      "     |      \n",
      "     |      :param inst:\n",
      "     |          If given, its current trait values will be used in place of\n",
      "     |          the class default.\n",
      "     |      :param helptext:\n",
      "     |          If not given, uses the `help` attribute of the current trait.\n",
      "     |  \n",
      "     |  class_print_help(inst: 'HasTraits | None' = None) -> 'None' from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get the help string for a single trait and print it.\n",
      "     |  \n",
      "     |  section_names() -> 'list[str]' from traitlets.traitlets.MetaHasTraits\n",
      "     |      return section names as a list\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from traitlets.config.configurable.Configurable:\n",
      "     |  \n",
      "     |  config\n",
      "     |  \n",
      "     |  parent\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from traitlets.traitlets.HasTraits:\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'dict[str, t.Any]'\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'dict[str, t.Any]') -> 'None'\n",
      "     |  \n",
      "     |  add_traits(self, **traits: 't.Any') -> 'None'\n",
      "     |      Dynamically add trait attributes to the HasTraits instance.\n",
      "     |  \n",
      "     |  has_trait(self, name: 'str') -> 'bool'\n",
      "     |      Returns True if the object has a trait with the specified name.\n",
      "     |  \n",
      "     |  hold_trait_notifications(self) -> 't.Any'\n",
      "     |      Context manager for bundling trait change notifications and cross\n",
      "     |      validation.\n",
      "     |      \n",
      "     |      Use this when doing multiple trait assignments (init, config), to avoid\n",
      "     |      race conditions in trait notifiers requesting other trait values.\n",
      "     |      All trait notifications will fire after all values have been assigned.\n",
      "     |  \n",
      "     |  notify_change(self, change: 'Bunch') -> 'None'\n",
      "     |      Notify observers of a change event\n",
      "     |  \n",
      "     |  observe(self, handler: 't.Callable[..., t.Any]', names: 'Sentinel | str | t.Iterable[Sentinel | str]' = traitlets.All, type: 'Sentinel | str' = 'change') -> 'None'\n",
      "     |      Setup a handler to be called when a trait changes.\n",
      "     |      \n",
      "     |      This is used to setup dynamic notifications of trait changes.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      handler : callable\n",
      "     |          A callable that is called when a trait changes. Its\n",
      "     |          signature should be ``handler(change)``, where ``change`` is a\n",
      "     |          dictionary. The change dictionary at least holds a 'type' key.\n",
      "     |          * ``type``: the type of notification.\n",
      "     |          Other keys may be passed depending on the value of 'type'. In the\n",
      "     |          case where type is 'change', we also have the following keys:\n",
      "     |          * ``owner`` : the HasTraits instance\n",
      "     |          * ``old`` : the old value of the modified trait attribute\n",
      "     |          * ``new`` : the new value of the modified trait attribute\n",
      "     |          * ``name`` : the name of the modified trait attribute.\n",
      "     |      names : list, str, All\n",
      "     |          If names is All, the handler will apply to all traits.  If a list\n",
      "     |          of str, handler will apply to all names in the list.  If a\n",
      "     |          str, the handler will apply just to that name.\n",
      "     |      type : str, All (default: 'change')\n",
      "     |          The type of notification to filter by. If equal to All, then all\n",
      "     |          notifications are passed to the observe handler.\n",
      "     |  \n",
      "     |  on_trait_change(self, handler: 'EventHandler | None' = None, name: 'Sentinel | str | None' = None, remove: 'bool' = False) -> 'None'\n",
      "     |      DEPRECATED: Setup a handler to be called when a trait changes.\n",
      "     |      \n",
      "     |      This is used to setup dynamic notifications of trait changes.\n",
      "     |      \n",
      "     |      Static handlers can be created by creating methods on a HasTraits\n",
      "     |      subclass with the naming convention '_[traitname]_changed'.  Thus,\n",
      "     |      to create static handler for the trait 'a', create the method\n",
      "     |      _a_changed(self, name, old, new) (fewer arguments can be used, see\n",
      "     |      below).\n",
      "     |      \n",
      "     |      If `remove` is True and `handler` is not specified, all change\n",
      "     |      handlers for the specified name are uninstalled.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      handler : callable, None\n",
      "     |          A callable that is called when a trait changes.  Its\n",
      "     |          signature can be handler(), handler(name), handler(name, new),\n",
      "     |          handler(name, old, new), or handler(name, old, new, self).\n",
      "     |      name : list, str, None\n",
      "     |          If None, the handler will apply to all traits.  If a list\n",
      "     |          of str, handler will apply to all names in the list.  If a\n",
      "     |          str, the handler will apply just to that name.\n",
      "     |      remove : bool\n",
      "     |          If False (the default), then install the handler.  If True\n",
      "     |          then unintall it.\n",
      "     |  \n",
      "     |  set_trait(self, name: 'str', value: 't.Any') -> 'None'\n",
      "     |      Forcibly sets trait attribute, including read-only attributes.\n",
      "     |  \n",
      "     |  setup_instance(*args: 't.Any', **kwargs: 't.Any') -> 'None'\n",
      "     |      This is called **before** self.__init__ is called.\n",
      "     |  \n",
      "     |  trait_defaults(self, *names: 'str', **metadata: 't.Any') -> 'dict[str, t.Any] | Sentinel'\n",
      "     |      Return a trait's default value or a dictionary of them\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Dynamically generated default values may\n",
      "     |      depend on the current state of the object.\n",
      "     |  \n",
      "     |  trait_has_value(self, name: 'str') -> 'bool'\n",
      "     |      Returns True if the specified trait has a value.\n",
      "     |      \n",
      "     |      This will return false even if ``getattr`` would return a\n",
      "     |      dynamically generated default value. These default values\n",
      "     |      will be recognized as existing only after they have been\n",
      "     |      generated.\n",
      "     |      \n",
      "     |      Example\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |          class MyClass(HasTraits):\n",
      "     |              i = Int()\n",
      "     |      \n",
      "     |      \n",
      "     |          mc = MyClass()\n",
      "     |          assert not mc.trait_has_value(\"i\")\n",
      "     |          mc.i  # generates a default value\n",
      "     |          assert mc.trait_has_value(\"i\")\n",
      "     |  \n",
      "     |  trait_metadata(self, traitname: 'str', key: 'str', default: 't.Any' = None) -> 't.Any'\n",
      "     |      Get metadata values for trait by key.\n",
      "     |  \n",
      "     |  trait_names(self, **metadata: 't.Any') -> 'list[str]'\n",
      "     |      Get a list of all the names of this class' traits.\n",
      "     |  \n",
      "     |  trait_values(self, **metadata: 't.Any') -> 'dict[str, t.Any]'\n",
      "     |      A ``dict`` of trait names and their values.\n",
      "     |      \n",
      "     |      The metadata kwargs allow functions to be passed in which\n",
      "     |      filter traits based on metadata values.  The functions should\n",
      "     |      take a single value as an argument and return a boolean.  If\n",
      "     |      any function returns False, then the trait is not included in\n",
      "     |      the output.  If a metadata key doesn't exist, None will be passed\n",
      "     |      to the function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A ``dict`` of trait names and their values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Trait values are retrieved via ``getattr``, any exceptions raised\n",
      "     |      by traits or the operations they may trigger will result in the\n",
      "     |      absence of a trait value in the result ``dict``.\n",
      "     |  \n",
      "     |  traits(self, **metadata: 't.Any') -> 'dict[str, TraitType[t.Any, t.Any]]'\n",
      "     |      Get a ``dict`` of all the traits of this class.  The dictionary\n",
      "     |      is keyed on the name and the values are the TraitType objects.\n",
      "     |      \n",
      "     |      The TraitTypes returned don't know anything about the values\n",
      "     |      that the various HasTrait's instances are holding.\n",
      "     |      \n",
      "     |      The metadata kwargs allow functions to be passed in which\n",
      "     |      filter traits based on metadata values.  The functions should\n",
      "     |      take a single value as an argument and return a boolean.  If\n",
      "     |      any function returns False, then the trait is not included in\n",
      "     |      the output.  If a metadata key doesn't exist, None will be passed\n",
      "     |      to the function.\n",
      "     |  \n",
      "     |  unobserve(self, handler: 't.Callable[..., t.Any]', names: 'Sentinel | str | t.Iterable[Sentinel | str]' = traitlets.All, type: 'Sentinel | str' = 'change') -> 'None'\n",
      "     |      Remove a trait change handler.\n",
      "     |      \n",
      "     |      This is used to unregister handlers to trait change notifications.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      handler : callable\n",
      "     |          The callable called when a trait attribute changes.\n",
      "     |      names : list, str, All (default: All)\n",
      "     |          The names of the traits for which the specified handler should be\n",
      "     |          uninstalled. If names is All, the specified handler is uninstalled\n",
      "     |          from the list of notifiers corresponding to all changes.\n",
      "     |      type : str or All (default: 'change')\n",
      "     |          The type of notification to filter by. If All, the specified handler\n",
      "     |          is uninstalled from the list of notifiers corresponding to all types.\n",
      "     |  \n",
      "     |  unobserve_all(self, name: 'str | t.Any' = traitlets.All) -> 'None'\n",
      "     |      Remove trait change handlers of any type for the specified name.\n",
      "     |      If name is not specified, removes all trait notifiers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from traitlets.traitlets.HasTraits:\n",
      "     |  \n",
      "     |  class_own_trait_events(name: 'str') -> 'dict[str, EventHandler]' from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get a dict of all event handlers defined on this class, not a parent.\n",
      "     |      \n",
      "     |      Works like ``event_handlers``, except for excluding traits from parents.\n",
      "     |  \n",
      "     |  class_own_traits(**metadata: 't.Any') -> 'dict[str, TraitType[t.Any, t.Any]]' from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get a dict of all the traitlets defined on this class, not a parent.\n",
      "     |      \n",
      "     |      Works like `class_traits`, except for excluding traits from parents.\n",
      "     |  \n",
      "     |  class_trait_names(**metadata: 't.Any') -> 'list[str]' from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get a list of all the names of this class' traits.\n",
      "     |      \n",
      "     |      This method is just like the :meth:`trait_names` method,\n",
      "     |      but is unbound.\n",
      "     |  \n",
      "     |  class_traits(**metadata: 't.Any') -> 'dict[str, TraitType[t.Any, t.Any]]' from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get a ``dict`` of all the traits of this class.  The dictionary\n",
      "     |      is keyed on the name and the values are the TraitType objects.\n",
      "     |      \n",
      "     |      This method is just like the :meth:`traits` method, but is unbound.\n",
      "     |      \n",
      "     |      The TraitTypes returned don't know anything about the values\n",
      "     |      that the various HasTrait's instances are holding.\n",
      "     |      \n",
      "     |      The metadata kwargs allow functions to be passed in which\n",
      "     |      filter traits based on metadata values.  The functions should\n",
      "     |      take a single value as an argument and return a boolean.  If\n",
      "     |      any function returns False, then the trait is not included in\n",
      "     |      the output.  If a metadata key doesn't exist, None will be passed\n",
      "     |      to the function.\n",
      "     |  \n",
      "     |  trait_events(name: 'str | None' = None) -> 'dict[str, EventHandler]' from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get a ``dict`` of all the event handlers of this class.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : str (default: None)\n",
      "     |          The name of a trait of this class. If name is ``None`` then all\n",
      "     |          the event handlers of this class will be returned instead.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The event handlers associated with a trait name, or all event handlers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from traitlets.traitlets.HasTraits:\n",
      "     |  \n",
      "     |  cross_validation_lock\n",
      "     |      A contextmanager for running a block with our cross validation lock set\n",
      "     |      to True.\n",
      "     |      \n",
      "     |      At the end of the block, the lock's value is restored to its value\n",
      "     |      prior to entering the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from traitlets.traitlets.HasDescriptors:\n",
      "     |  \n",
      "     |  __new__(*args: 't.Any', **kwargs: 't.Any') -> 't.Any'\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from traitlets.traitlets.HasDescriptors:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    load_ipython_extension(ipython)\n",
      "        Any module file that define a function named `load_ipython_extension`\n",
      "        can be loaded via `%load_ext module.path` or be configured to be\n",
      "        autoloaded by IPython at startup time.\n",
      "\n",
      "VERSION\n",
      "    1.8.2\n",
      "\n",
      "FILE\n",
      "    /home/ian/miniconda3/envs/coursehpp/lib/python3.11/site-packages/ipython_memory_usage/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ipython_memory_usage\n",
    "help(ipython_memory_usage) # or ipython_memory_usage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3faa440f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling IPython Memory Usage, use %imu_start to begin, %imu_stop to end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'IPython Memory Usage started'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [2] used 0.9 MiB RAM in 0.13s (system mean cpu 0%, single max cpu 0%), peaked 0.0 MiB above final usage, current RAM usage now 66.1 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext ipython_memory_usage\n",
    "%imu_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ce9d2",
   "metadata": {},
   "source": [
    "# Importing packages uses some RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65a2110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [3] used 15.3 MiB RAM in 0.19s (system mean cpu 0%, single max cpu 0%), peaked 0.0 MiB above final usage, current RAM usage now 81.4 MiB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # note that importing a package will increase total RAM usage a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d9ac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [4] used 54.1 MiB RAM in 0.39s (system mean cpu 8%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 135.5 MiB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # note that importing Pandas uses more RAM than importing numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ca123c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [5] used 0.0 MiB RAM in 0.10s (system mean cpu 7%, single max cpu 27%), peaked 0.0 MiB above final usage, current RAM usage now 135.5 MiB\n"
     ]
    }
   ],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa3e401",
   "metadata": {},
   "source": [
    "# Making a large array uses a predictable amount of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9663af97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [6] used 763.2 MiB RAM in 0.28s (system mean cpu 8%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 898.7 MiB\n"
     ]
    }
   ],
   "source": [
    "# if we make a big array - 100M items * 8 byte floats, this cell\n",
    "# uses circa 800MB (often 760 MiB - note mibi-bytes as used in the underlying memory_profiler tool)\n",
    "# The total RAM usage grows by roughly this amount\n",
    "arr = np.ones(100_000_000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d23b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [7] used -762.9 MiB RAM in 0.10s (system mean cpu 8%, single max cpu 20%), peaked 762.9 MiB above final usage, current RAM usage now 135.7 MiB\n"
     ]
    }
   ],
   "source": [
    "# deleting arr reduces RAM usage by roughly the expected amount and\n",
    "# total RAM usage should drop back down\n",
    "del arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3b516f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [8] used 763.0 MiB RAM in 0.27s (system mean cpu 8%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 898.8 MiB\n"
     ]
    }
   ],
   "source": [
    "# if we make it again, RAM usage goes up again\n",
    "arr = np.ones(100_000_000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1bbaff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [9] used -762.9 MiB RAM in 0.10s (system mean cpu 5%, single max cpu 20%), peaked 762.9 MiB above final usage, current RAM usage now 135.8 MiB\n"
     ]
    }
   ],
   "source": [
    "del arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a733e50",
   "metadata": {},
   "source": [
    "# Making a big random array takes RAM + time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57518265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.11397493 -0.19617328  1.41230994  0.72710602  0.6042617 ] float64\n",
      "In [10] used 763.1 MiB RAM in 3.25s (system mean cpu 10%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 898.9 MiB\n"
     ]
    }
   ],
   "source": [
    "# creating random items takes some time, after \"used ... RAM\" note \"3s\" or so for several seconds\n",
    "arr = np.random.normal(size=100_000_000)\n",
    "print(arr[:5], arr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced0369",
   "metadata": {},
   "source": [
    "# Intermediate calculations can cost additional temporary RAM \n",
    "\n",
    "**NOTE** this section may work different if you're on Windows (if so - please report back to Ian by raising a bug and noting the difference.\n",
    "\n",
    "On some platforms, e.g. Linux as used here, temporary intermediates can be reused in-place reducing the overall memory allocation: https://docs.scipy.org/doc/numpy-1.13.0/release.html#highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84828ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [11] used 0.1 MiB RAM in 0.10s (system mean cpu 5%, single max cpu 40%), peaked 0.0 MiB above final usage, current RAM usage now 899.0 MiB\n"
     ]
    }
   ],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c96ec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [12] used 763.6 MiB RAM in 0.76s (system mean cpu 10%, single max cpu 100%), peaked 762.9 MiB above final usage, current RAM usage now 1662.6 MiB\n"
     ]
    }
   ],
   "source": [
    "# (arr * 2) will allocate a new 762MiB array\n",
    "# (arr * 3) will also allocate another 762MiB (so +1.4GB in total)\n",
    "# the (arr * 2) array can be overwritten in-place for the division, so \n",
    "# a third temporary is _not_ needed\n",
    "# the final result (costing 762MiB) is assigned to arr_result\n",
    "# therefore we report \"used 762MiB\" at the end of the cell's execution\n",
    "# plus \"peaked 762MiB above final usage\" due to the second temporary,\n",
    "# so 1.4GB max was used during execution.\n",
    "arr_result = (arr * 2) / (arr * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccfd36b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [13] used -762.9 MiB RAM in 0.11s (system mean cpu 9%, single max cpu 27%), peaked 762.9 MiB above final usage, current RAM usage now 899.7 MiB\n"
     ]
    }
   ],
   "source": [
    "del arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d0937da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [14] used -762.9 MiB RAM in 0.11s (system mean cpu 6%, single max cpu 30%), peaked 762.9 MiB above final usage, current RAM usage now 136.8 MiB\n"
     ]
    }
   ],
   "source": [
    "del arr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f96940",
   "metadata": {},
   "source": [
    "# Pandas DataFrames can be costly on RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6bbc35",
   "metadata": {},
   "source": [
    "## Example with deleting columns\n",
    "\n",
    "Props to Jamie Brunning for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f285be45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [15] used 0.0 MiB RAM in 0.10s (system mean cpu 8%, single max cpu 36%), peaked 0.0 MiB above final usage, current RAM usage now 136.8 MiB\n"
     ]
    }
   ],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a365395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [16] used 3051.8 MiB RAM in 12.30s (system mean cpu 9%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 3188.6 MiB\n"
     ]
    }
   ],
   "source": [
    "arr_several_cols = np.random.normal(size=(100_000_000, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1751039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000000, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [17] used 0.0 MiB RAM in 0.10s (system mean cpu 7%, single max cpu 44%), peaked 0.0 MiB above final usage, current RAM usage now 3188.6 MiB\n"
     ]
    }
   ],
   "source": [
    "arr_several_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27cb29ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cost per column 800,000,000 bytes'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [18] used 0.0 MiB RAM in 0.10s (system mean cpu 10%, single max cpu 50%), peaked 0.0 MiB above final usage, current RAM usage now 3188.6 MiB\n"
     ]
    }
   ],
   "source": [
    "f\"Cost per column {int(arr_several_cols.data.nbytes / arr_several_cols.shape[1]):,} bytes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb36e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   a       float64\n",
      " 1   b       float64\n",
      " 2   c       float64\n",
      " 3   d       float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.0 GB\n",
      "In [19] used 2.1 MiB RAM in 0.11s (system mean cpu 8%, single max cpu 33%), peaked 0.0 MiB above final usage, current RAM usage now 3190.7 MiB\n"
     ]
    }
   ],
   "source": [
    "# The DataFrame in this case is a thin wrapper over the numpy array\n",
    "# and costs little extra RAM\n",
    "df = pd.DataFrame(arr_several_cols, columns=list(string.ascii_lowercase)[:arr_several_cols.shape[1]])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4579f39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [20] used 0.0 MiB RAM in 0.10s (system mean cpu 9%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 3190.7 MiB\n"
     ]
    }
   ],
   "source": [
    "# use Jupyter's xdel to remove all references of our expensive array, just in case\n",
    "# (but not in this case) it is also referred to in an Out[] history item\n",
    "%xdel arr_several_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a42d2330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   a       float64\n",
      " 1   b       float64\n",
      " 2   c       float64\n",
      " 3   d       float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.0 GB\n",
      "In [21] used 0.0 MiB RAM in 0.11s (system mean cpu 11%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 3190.7 MiB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "810fe2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [22] used 0.0 MiB RAM in 0.10s (system mean cpu 9%, single max cpu 30%), peaked 0.0 MiB above final usage, current RAM usage now 3190.7 MiB\n"
     ]
    }
   ],
   "source": [
    "# deleting a column \n",
    "# note that no RAM is freed up!\n",
    "del df['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a10f1792-9bbe-4ced-85cf-09fa566a055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   b       float64\n",
      " 1   c       float64\n",
      " 2   d       float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 2.2 GB\n",
      "In [23] used 0.0 MiB RAM in 0.11s (system mean cpu 12%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 3190.7 MiB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3f87a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [24] used 0.0 MiB RAM in 0.14s (system mean cpu 11%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 3190.7 MiB\n"
     ]
    }
   ],
   "source": [
    "# we get no benefit by forcing a collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f33f9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   b       float64\n",
      " 1   c       float64\n",
      " 2   d       float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 2.2 GB\n",
      "In [25] used 0.0 MiB RAM in 0.11s (system mean cpu 12%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 3190.7 MiB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b20a4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [26] used 0.0 MiB RAM in 0.10s (system mean cpu 11%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 3190.7 MiB\n"
     ]
    }
   ],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c2dfe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [27] used -1525.7 MiB RAM in 1.00s (system mean cpu 17%, single max cpu 100%), peaked 2937.5 MiB above final usage, current RAM usage now 1665.0 MiB\n"
     ]
    }
   ],
   "source": [
    "# using drop with inplace=False (the default) returns a copied DataFrame, if you don't use\n",
    "# this then maybe you end up with multiple DataFrames consuming RAM in a confusing fashion\n",
    "# e.g. you might have done `df2 = df.drop...` and then you've got the unmodified original\n",
    "# plus the modified df2 in the local namespace\n",
    "# We see total RAM usage drop by circa 800MB, the cost of 1 column, plus the other column (a)\n",
    "# maybe the usage of drop forces a flush on any internal caching in pandas?\n",
    "df = df.drop(columns=['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8fa1677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   c       float64\n",
      " 1   d       float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.5 GB\n",
      "In [28] used 0.0 MiB RAM in 0.11s (system mean cpu 11%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 1665.0 MiB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5891371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [29] used -762.9 MiB RAM in 0.44s (system mean cpu 14%, single max cpu 80%), peaked 762.9 MiB above final usage, current RAM usage now 902.1 MiB\n"
     ]
    }
   ],
   "source": [
    "# dropping in-place is probably more sensible, we recover another circa 800MB\n",
    "df.drop(columns=['c'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c0453e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   d       float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 762.9 MB\n",
      "In [30] used 0.0 MiB RAM in 0.11s (system mean cpu 0%, single max cpu 0%), peaked 0.0 MiB above final usage, current RAM usage now 902.1 MiB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50ba3e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [31] used 0.0 MiB RAM in 0.10s (system mean cpu 0%, single max cpu 0%), peaked 0.0 MiB above final usage, current RAM usage now 902.1 MiB\n"
     ]
    }
   ],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59e0c880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [32] used -762.9 MiB RAM in 0.11s (system mean cpu 0%, single max cpu 0%), peaked 0.0 MiB above final usage, current RAM usage now 139.1 MiB\n"
     ]
    }
   ],
   "source": [
    "# now we get back to where we were before we made the DataFrame and the array\n",
    "df.drop(columns=['d'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fed661",
   "metadata": {},
   "source": [
    "# Diagnostics\n",
    "\n",
    "`%xdel my_df` will delete all references of `my_df` from the namespace including those in the Out[] history buffer, this does more cleaning than just using `del my_df`.\n",
    "\n",
    "`%reset` will reset all variables and imported modules, it is like starting a new kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a6a2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable               Type         Data/Info\n",
      "---------------------------------------------\n",
      "df                     DataFrame    Empty DataFrame\\nColumns:<...>0000000 rows x 0 columns]\n",
      "gc                     module       <module 'gc' (built-in)>\n",
      "ipython_memory_usage   module       <module 'ipython_memory_u<...>emory_usage/__init__.py'>\n",
      "np                     module       <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "pd                     module       <module 'pandas' from '/h<...>ages/pandas/__init__.py'>\n",
      "string                 module       <module 'string' from '/h<...>ib/python3.11/string.py'>\n",
      "In [33] used 0.0 MiB RAM in 0.10s (system mean cpu 6%, single max cpu 22%), peaked 0.0 MiB above final usage, current RAM usage now 139.1 MiB\n"
     ]
    }
   ],
   "source": [
    "# %whos shows what's in the local namespace\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "542391ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [34] used 0.0 MiB RAM in 0.10s (system mean cpu 5%, single max cpu 25%), peaked 0.0 MiB above final usage, current RAM usage now 139.1 MiB\n"
     ]
    }
   ],
   "source": [
    "# we can use %xdel to safely remove all references including those that might be (but not in this case)\n",
    "# in the Out[] history buffer\n",
    "%xdel df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b1fb436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [35] used 0.0 MiB RAM in 0.10s (system mean cpu 6%, single max cpu 20%), peaked 0.0 MiB above final usage, current RAM usage now 139.1 MiB\n"
     ]
    }
   ],
   "source": [
    "#%imu_stop\n",
    "#'IPython Memory Usage stopped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1c17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
