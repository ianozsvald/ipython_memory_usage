{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25531fd7",
   "metadata": {},
   "source": [
    "# Short demo of using `ipython_memory_usage` to diagnose numpy and Pandas RAM usage\n",
    "\n",
    "Author Ian uses this tool in his Higher Performance Python training (https://ianozsvald.com/training/) and it is mentioned in his High Performance Python (2nd ed, O'Reilly) technical book.\n",
    "\n",
    "We can use it to understand how much RAM we're currently using and which of several alternate ways to solve a problem in complex tools might be the most RAM efficient solutions.\n",
    "\n",
    "* `total RAM usage` is the current RAM usage at the end of that cell's execution\n",
    "* `used` shows the difference between the _last_ `total RAM usage` and this one\n",
    "* `peaked` shows any during-execution peak _above_ the resulting `total RAM usage` (i.e. hidden RAM usage that might catch you out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2954dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package ipython_memory_usage:\n",
      "\n",
      "NAME\n",
      "    ipython_memory_usage - Profile mem usage envelope of IPython commands and report interactively\n",
      "\n",
      "DESCRIPTION\n",
      "    Use \n",
      "    In[] import ipython_memory_usage \n",
      "    In[] %ipython_memory_usage_start # invoke magic-based tracking and\n",
      "    # %ipython_memory_usage_stop to disable\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    ipython_memory_usage\n",
      "    ipython_memory_usage_perf\n",
      "    perf_process\n",
      "\n",
      "SUBMODULES\n",
      "    imu\n",
      "\n",
      "FUNCTIONS\n",
      "    ipython_memory_usage_start(line, cell=None)\n",
      "    \n",
      "    ipython_memory_usage_stop(line, cell=None)\n",
      "\n",
      "FILE\n",
      "    /home/ian/workspace/personal_projects/ipython_memory_usage_base/ipython_memory_usage/ipython_memory_usage_dev/ipython_memory_usage/src/ipython_memory_usage/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ipython_memory_usage\n",
    "help(ipython_memory_usage) # or ipython_memory_usage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3faa440f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory profile enabled'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [2] used 0.1562 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 48.67 MiB\n"
     ]
    }
   ],
   "source": [
    "%ipython_memory_usage_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ce9d2",
   "metadata": {},
   "source": [
    "# Importing packages uses some RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65a2110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [3] used 12.0039 MiB RAM in 0.24s, peaked 0.00 MiB above current, total RAM usage 60.68 MiB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # note that importing a package will increase total RAM usage a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d9ac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [4] used 24.3984 MiB RAM in 0.35s, peaked 0.00 MiB above current, total RAM usage 85.07 MiB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # note that importing Pandas uses more RAM than importing numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ca123c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [5] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 85.07 MiB\n"
     ]
    }
   ],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa3e401",
   "metadata": {},
   "source": [
    "# Making a large array uses a predictable amount of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9663af97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [6] used 763.3750 MiB RAM in 0.25s, peaked 0.00 MiB above current, total RAM usage 848.45 MiB\n"
     ]
    }
   ],
   "source": [
    "# if we make a big array - 100M items * 8 byte floats, this cell\n",
    "# uses circa 800MB (often 760 MiB - note mibi-bytes as used in the underlying memory_profiler tool)\n",
    "# The total RAM usage grows by roughly this amount\n",
    "arr = np.ones(100_000_000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d23b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [7] used -762.9297 MiB RAM in 0.11s, peaked 762.93 MiB above current, total RAM usage 85.52 MiB\n"
     ]
    }
   ],
   "source": [
    "# deleting arr reduces RAM usage by roughly the expected amount and\n",
    "# total RAM usage should drop back down\n",
    "del arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3b516f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [8] used 763.0039 MiB RAM in 0.24s, peaked 0.00 MiB above current, total RAM usage 848.52 MiB\n"
     ]
    }
   ],
   "source": [
    "# if we make it again, RAM usage goes up again\n",
    "arr = np.ones(100_000_000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1bbaff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [9] used -762.6836 MiB RAM in 0.11s, peaked 762.68 MiB above current, total RAM usage 85.84 MiB\n"
     ]
    }
   ],
   "source": [
    "del arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a733e50",
   "metadata": {},
   "source": [
    "# Making a big random array takes RAM + time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57518265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14678642  0.14768542 -1.1194974  -0.83116093 -0.30498602] float64\n",
      "In [10] used 763.0117 MiB RAM in 3.26s, peaked 0.00 MiB above current, total RAM usage 848.85 MiB\n"
     ]
    }
   ],
   "source": [
    "# creating random items takes some time, after \"used ... RAM\" note \"3s\" or so for several seconds\n",
    "arr = np.random.normal(size=100_000_000)\n",
    "print(arr[:5], arr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced0369",
   "metadata": {},
   "source": [
    "# Intermediate calculations can cost additional temporary RAM \n",
    "\n",
    "**NOTE** this section may work different if you're on Windows (if so - please report back to Ian by raising a bug and noting the difference.\n",
    "\n",
    "On some platforms, e.g. Linux as used here, temporary intermediates can be reused in-place reducing the overall memory allocation: https://docs.scipy.org/doc/numpy-1.13.0/release.html#highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84828ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [11] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 848.85 MiB\n"
     ]
    }
   ],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c96ec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [12] used 763.1992 MiB RAM in 0.58s, peaked 762.68 MiB above current, total RAM usage 1612.05 MiB\n"
     ]
    }
   ],
   "source": [
    "# arr*2 and arr*3 both have to be stored somewhere before the division can occur\n",
    "# so two more circa 762MiB arrays are made temporarily, this is reported\n",
    "# as \"peaked 762MiB above current\"\n",
    "# before they can be discard. arr_result references the final result\n",
    "# so overall we add 762MiB to the process\n",
    "# we only add 762MiB, not 762MiB*2, as on Linux we can intelligently reuse\n",
    "# one of the temporaries (else we'd peak at 762*2 MiB)\n",
    "\n",
    "# we report \"used 762...MiB\" as the final arr_result adds this to the process\n",
    "# so overall we're now _at_ 1.6GB but we actually peaked at 1.6+0.7 == 2.3GB \n",
    "# whilst this cell executed\n",
    "# if your code crashes with an out of memory exception, it could be caused\n",
    "# by a situation like this\n",
    "arr_result = (arr * 2) / (arr * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccfd36b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [13] used -762.9219 MiB RAM in 0.10s, peaked 762.92 MiB above current, total RAM usage 849.13 MiB\n"
     ]
    }
   ],
   "source": [
    "del arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d0937da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [14] used -762.9180 MiB RAM in 0.10s, peaked 762.92 MiB above current, total RAM usage 86.21 MiB\n"
     ]
    }
   ],
   "source": [
    "del arr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f96940",
   "metadata": {},
   "source": [
    "# Pandas DataFrames can be costly on RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6bbc35",
   "metadata": {},
   "source": [
    "## Example with deleting columns\n",
    "\n",
    "Props to Jamie Brunning for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f285be45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [15] used 0.1406 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 86.35 MiB\n"
     ]
    }
   ],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a365395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [16] used 3051.7812 MiB RAM in 12.77s, peaked 0.00 MiB above current, total RAM usage 3138.13 MiB\n"
     ]
    }
   ],
   "source": [
    "arr_several_cols = np.random.normal(size=(100_000_000, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1751039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000000, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [17] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 3138.13 MiB\n"
     ]
    }
   ],
   "source": [
    "arr_several_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27cb29ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cost per column 800,000,000 bytes'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [18] used 0.0156 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 3138.15 MiB\n"
     ]
    }
   ],
   "source": [
    "f\"Cost per column {int(arr_several_cols.data.nbytes / arr_several_cols.shape[1]):,} bytes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb36e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   a       float64\n",
      " 1   b       float64\n",
      " 2   c       float64\n",
      " 3   d       float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.0 GB\n",
      "In [19] used 1.2383 MiB RAM in 0.12s, peaked 0.00 MiB above current, total RAM usage 3139.39 MiB\n"
     ]
    }
   ],
   "source": [
    "# The DataFrame in this case is a thin wrapper over the numpy array\n",
    "# and costs little extra RAM\n",
    "df = pd.DataFrame(arr_several_cols, columns=list(string.ascii_lowercase)[:arr_several_cols.shape[1]])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4579f39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [20] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 3139.39 MiB\n"
     ]
    }
   ],
   "source": [
    "# use Jupyter's xdel to remove all references of our expensive array, just in case\n",
    "# (but not in this case) it is also referred to in an Out[] history item\n",
    "%xdel arr_several_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a42d2330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   a       float64\n",
      " 1   b       float64\n",
      " 2   c       float64\n",
      " 3   d       float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.0 GB\n",
      "In [21] used 0.0000 MiB RAM in 0.12s, peaked 0.00 MiB above current, total RAM usage 3139.39 MiB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "810fe2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [22] used 2289.1992 MiB RAM in 1.04s, peaked 0.00 MiB above current, total RAM usage 5428.59 MiB\n"
     ]
    }
   ],
   "source": [
    "# using del is surprisingly expensive\n",
    "# total RAM usage goes up by circa 1.5GB-2GB (>2x the cost of 1 column) \n",
    "# DOES ANYONE KNOW WHAT'S HAPPENING BEHIND THE SCENES HERE?\n",
    "# THE NEXT 2 CELLS SHOW IT ISN'T BEING QUICKLY GARBAGE COLLECTED\n",
    "# note also that using del seems to take more seconds than using df.drop (a few cells below)\n",
    "# possibly internally there's now (somehow) a 4-column original array _and_ a\n",
    "# 3 column resulting array (in the BlockManager?) costing 7-columns (i.e. circa 800MB*7 == circa 5.6GB)\n",
    "del df['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3f87a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [23] used 0.0430 MiB RAM in 0.14s, peaked 0.00 MiB above current, total RAM usage 5428.63 MiB\n"
     ]
    }
   ],
   "source": [
    "# we get no benefit by forcing a collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f33f9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   b       float64\n",
      " 1   c       float64\n",
      " 2   d       float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 2.2 GB\n",
      "In [24] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 5428.63 MiB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b20a4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [25] used 0.0352 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 5428.66 MiB\n"
     ]
    }
   ],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c2dfe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [26] used -3814.5781 MiB RAM in 0.52s, peaked 3814.58 MiB above current, total RAM usage 1614.09 MiB\n"
     ]
    }
   ],
   "source": [
    "# using drop with inplace=False (the default) returns a copied DataFrame, if you don't use\n",
    "# this then maybe you end up with multiple DataFrames consuming RAM in a confusing fashion\n",
    "# e.g. you might have done `df2 = df.drop...` and then you've got the unmodified original\n",
    "# plus the modified df2 in the local namespace\n",
    "# We see total RAM usage drop by circa 800MB, the cost of 1 column, plus a lot more...\n",
    "# which is a mystery to me!\n",
    "# maybe the usage of drop forces a flush on any internal caching in pandas?\n",
    "df = df.drop(columns=['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8fa1677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   c       float64\n",
      " 1   d       float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.5 GB\n",
      "In [27] used -0.0156 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 1614.07 MiB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5891371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [28] used -762.9336 MiB RAM in 0.32s, peaked 0.00 MiB above current, total RAM usage 851.14 MiB\n"
     ]
    }
   ],
   "source": [
    "# dropping in-place is probably more sensible, we recover another circa 800MB\n",
    "df.drop(columns=['c'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c0453e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   d       float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 762.9 MB\n",
      "In [29] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 851.14 MiB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50ba3e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [30] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 851.14 MiB\n"
     ]
    }
   ],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59e0c880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [31] used -762.9258 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 88.21 MiB\n"
     ]
    }
   ],
   "source": [
    "# now we get back to where we were before we made the DataFrame and the array\n",
    "df.drop(columns=['d'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fed661",
   "metadata": {},
   "source": [
    "# Diagnostics\n",
    "\n",
    "`%xdel my_df` will delete all references of `my_df` from the namespace including those in the Out[] history buffer, this does more cleaning than just using `del my_df`.\n",
    "\n",
    "`%reset` will reset all variables and imported modules, it is like starting a new kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a6a2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable               Type         Data/Info\n",
      "---------------------------------------------\n",
      "df                     DataFrame    Empty DataFrame\\nColumns:<...>0000000 rows x 0 columns]\n",
      "gc                     module       <module 'gc' (built-in)>\n",
      "ipython_memory_usage   module       <module 'ipython_memory_u<...>emory_usage/__init__.py'>\n",
      "np                     module       <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "pd                     module       <module 'pandas' from '/h<...>ages/pandas/__init__.py'>\n",
      "string                 module       <module 'string' from '/h<...>lib/python3.9/string.py'>\n",
      "In [32] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 88.21 MiB\n"
     ]
    }
   ],
   "source": [
    "# %whos shows what's in the local namespace\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "542391ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [33] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 88.21 MiB\n"
     ]
    }
   ],
   "source": [
    "# we can use %xdel to safely remove all references including those that might be (but not in this case)\n",
    "# in the Out[] history buffer\n",
    "%xdel df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b1fb436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory profile disabled'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ipython_memory_usage_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1c17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
